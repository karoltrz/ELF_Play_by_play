{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d13170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display setup for visibility\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url adress to scrap\n",
    "page_info = 'https://europeanleague.football/live-games/220821-wroclaw-panthers-leipzig-kings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with chrome \n",
    "service = Service('./chromedriver.exe')\n",
    "service.start()\n",
    "driver = webdriver.Remote(service.service_url)\n",
    "driver.get(page_info)\n",
    "time.sleep(3)\n",
    "#clicking through cookies\n",
    "driver.find_element(By.XPATH,'.//*[@id=\"consentDialog\"]/div[2]/div[2]/div/div[2]/div/div[1]/div').click()\n",
    "time.sleep(3)\n",
    "#closing add\n",
    "driver.find_element(By.XPATH,'/html/body/div[23]/div[2]/div[2]').click()\n",
    "time.sleep(3)\n",
    "#moving the slider to show the drives info\n",
    "driver.find_element(By.XPATH,'/html/body/div[7]/div[2]/div[6]/a/div[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding details for all drives\n",
    "input_element = driver.find_elements(By.XPATH,'.//*[starts-with(@id, \"driveindex\")]/div[2]/div[7]')\n",
    "for item in input_element:\n",
    "    item.click()\n",
    "    time.sleep(1)\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to BS4\n",
    "soup = BeautifulSoup(page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping the data\n",
    "lists_all = soup.find('div', id='drives_by_quarter_inner')\n",
    "\n",
    "for item in lists_all:\n",
    "    dfs = []\n",
    "    lists_drive = lists_all.find_all('div', id=lambda x : x.startswith('driveindex') if x else False)\n",
    "    for drive in lists_drive:\n",
    "        elements = drive.find_all(class_=\"drives_plays_play\")\n",
    "        dane = []\n",
    "        qtr = drive.find_previous_sibling(\"h3\").text\n",
    "        team = drive.find('img', class_='drives teamlogo')['name']\n",
    "        drive_result = drive.find('div', class_='drives_cell drivestart').text\n",
    "        drive_plays = drive.find('div', class_=\"drives_cell plays\").find_next(text=True).strip()\n",
    "        drive_yds = drive.find('div', class_=\"drives_cell yards\").find_next(text=True).strip()\n",
    "        drive_time = drive.find('div', class_=\"drives_cell totaltime\").find_next(text=True).strip()\n",
    "        columns = ['aa','play','bb','situation','dd','desc','cc']\n",
    "        for element in elements:\n",
    "            down = element.find('div', class_=\"drives_plays_play_next_step\").text\n",
    "            play = element.find('h4').text\n",
    "            desc = element.find('div', class_=\"drives_plays_play_desc\").text\n",
    "            dane.append(element)\n",
    "        \n",
    "        df = pd.DataFrame(dane,columns=columns)\n",
    "        df['qtr'] = qtr\n",
    "        df['drive_num'] = drive['id']\n",
    "        df['pos_team'] = team\n",
    "        df['drive_result'] = drive_result\n",
    "        df['drive_plays'] = drive_plays\n",
    "        df['drive_yds'] = drive_yds\n",
    "        df['drive_time'] = drive_time\n",
    "        dfs.append(df)\n",
    "        \n",
    "dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca48539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping not needed collumns\n",
    "dfs.drop(['aa', 'bb','cc', 'dd'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reseting and dropping index\n",
    "dfs.reset_index(inplace=True)\n",
    "dfs.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting column 'desc' into 5 columns \n",
    "dfs[['down','team2','yds_to_go','team4','field_pos']] = pd.DataFrame(dfs.desc.tolist(), index = dfs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9739af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using expload on new columns which contains lists into objects \n",
    "dfs = dfs.explode('play')\n",
    "dfs = dfs.explode('situation')\n",
    "dfs = dfs.explode('down')\n",
    "dfs = dfs.explode('yds_to_go')\n",
    "dfs = dfs.explode('field_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de703b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping some not needed empty columns\n",
    "dfs.drop(['desc', 'team2','team4'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data for 3 columns with constant data for the entire game (url) from the page_info (url)\n",
    "dfs['home_team'] = page_info.split('-')[4].strip().capitalize()\n",
    "dfs['away_team'] = page_info.split('-')[2].strip().capitalize()\n",
    "dfs['game_date'] = page_info.split('-')[1].strip().split('/')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6812c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving data to csv file\n",
    "if not os.path.isfile('elf_plays_2022_scrap.csv'):\n",
    "    dfs.to_csv('elf_plays_2022_scrap.csv', header='column_names')\n",
    "else: # else it exists so append without writing the header\n",
    "    dfs.to_csv('elf_plays_2022_scrap.csv', mode='a', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
