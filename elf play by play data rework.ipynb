{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac50ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display changes for visibility\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading csv file created in the process of scrapping with \"elf plays scrap\"\n",
    "df_play = pd.read_csv('elf_plays_2022_scrap.csv')\n",
    "df_game_info = pd.read_csv('elf_schedule_scrap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the unnamed column for index\n",
    "df_play = df_play.drop(['Unnamed: 0'],axis=1)\n",
    "df_game_info = df_game_info.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating game_id column in play by play df which will be used to merge dfs\n",
    "df_play['game_id'] = df_play['game_date'].astype(str).str.split(\"\").str[0:5].str.join(\"\")+df_play['away_team'].str.split(\"\").str[:4].str.join(\"\")+df_play['home_team'].str.split(\"\").str[:4].str.join(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d68c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dfs\n",
    "df = df_play.merge(df_game_info, on='game_id', how='left')\n",
    "#dropping duplicate columns left after merge and renaming unique ones (getting rid of \"_y\") \n",
    "df = df.drop(['away_team_x','home_team_x'], axis=1)\n",
    "df = df.rename(columns={'away_team_y': 'away_team', 'home_team_y': 'home_team', 'yds_to_go':'yds_to_1st_down'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6314ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating additional columns with data\n",
    "df['drive_num'] = df['drive_num'].str.split(\"_\").str[1:].str.join(\" \")\n",
    "df['situation'] = df['situation'].str.replace(\";\",',')\n",
    "df['passer'] = np.where(df['play'].str.contains('Pass'), df[\"situation\"].str.split(\" \").str[:2].str.join(\" \"), np.nan)\n",
    "df['receiver'] = df['situation'].str.extract(r'(?<=pass complete to\\s)(\\S*\\s\\S*)')\n",
    "df['intended_receiver'] = np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('pass incomplete'))), \n",
    "                           df[\"situation\"].str.split(\" \").str[5:7].str.join(\" \"),\n",
    "                            np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('pass complete'))), \n",
    "                           df[\"situation\"].str.split(\" \").str[5:7].str.join(\" \"), np.nan))\n",
    "df['pass_attempt'] = np.where((df['play'].str.contains('Pass')),1,0)\n",
    "df['pass_comp'] = np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('pass complete'))),1,0)\n",
    "df['passing_yds'] = np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('incomplete'))),0,\n",
    "                np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('no gain'))),0,\n",
    "                np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('loss of'))), \n",
    "                \"-\"+df[\"situation\"].str.extract(r'(?<=for loss of\\s)(\\S*)',expand=False),\n",
    "                np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('pass complete'))), \n",
    "                df[\"situation\"].str.extract(r'(?<=for\\s)(\\S*)',expand=False), np.nan))))\n",
    "df['rusher'] = np.where((df['play'].str.contains('Rush')&(df['situation'].str.contains('rush'))), \n",
    "                           df[\"situation\"].str.split(\" \").str[0:2].str.join(\" \"), np.nan)\n",
    "df['rush_yds'] = np.where((df['situation'].str.contains('rush for loss')), \n",
    "                           \"-\"+df[\"situation\"].str.extract(r'(?<=rush for loss of\\s)(\\S*)',expand=False),\n",
    "                            np.where((df['situation'].str.contains('rush for no gain')), 0,\n",
    "                           np.where((df['play'].str.contains('Rush')),\n",
    "                            df[\"situation\"].str.extract(r'(?<=rush for\\s)(\\S*)',expand=False),np.nan)))\n",
    "df['yds_gained_per_play'] = pd.to_numeric(df['rush_yds'].fillna(0))+pd.to_numeric(df['passing_yds'].fillna(0))\n",
    "df['td'] = np.where((df['situation'].str.contains('TOUCHDOWN')), 1, 0)\n",
    "df['pass_td'] = np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('TOUCHDOWN'))), 1, 0)\n",
    "df['rush_td'] = np.where((df['play'].str.contains('Rush')&(df['situation'].str.contains('TOUCHDOWN'))), 1, 0)\n",
    "df['extra_point_attempt'] = np.where((((df['play'].str.contains('Point after try')&\n",
    "            (df['situation'].str.contains('kick')))|(df['situation'].str.contains('kick attempt')))),1,0)\n",
    "df['extra_point_result'] = np.where((df['situation'].str.contains('kick attempt failed')),'failed',\n",
    "                    np.where((df['situation'].str.contains('kick attempt failed (blocked)')),'blocked',\n",
    "                    np.where((df['situation'].str.contains('kick attempt failed (fumbled)')),'fumbled',\n",
    "                    np.where((df['situation'].str.contains('kick attempt good')),'good',np.nan))))\n",
    "#df['2pt_attempt'] =   \n",
    "#df['2pt_attempt_result'] =                              \n",
    "df['fg_attempt'] = np.where((df['play'].str.contains('Field goal attempt')),1,0)\n",
    "df['fg_attempt_result'] = np.where((df['play'].str.contains('Field goal')&(df['situation'].str.contains('GOOD'))),'good',\n",
    "        np.where((df['play'].str.contains('Field goal')&(df['situation'].str.contains('MISSED'))),'missed',\n",
    "        np.where((df['play'].str.contains('Field goal')&(df['situation'].str.contains('BLOCKED'))),'blocked',np.nan)))\n",
    "df['fg_attempt_distance'] = np.where((df['play'].str.contains('Field goal attempt')),\n",
    "               (df[\"situation\"].str.extract(r'(?<=attempt from\\s)(\\S*)',expand=False)),0)\n",
    "df['fg_kicker'] = np.where((df['play'].str.contains('Field goal')),\n",
    "                            df[\"situation\"].str.extract(r'(\\S*\\s\\S*)(?=\\sfield)',expand=False),np.nan) \n",
    "df['kickoff_player'] = np.where((df['play'].str.contains('Kickoff')), \n",
    "                           df[\"situation\"].str.split(\" \").str[:2].str.join(\" \"), np.nan)\n",
    "df['kickoff_yds'] = np.where((df['play'].str.contains('Kickoff')), \n",
    "                           df[\"situation\"].str.split(\" \").str[3:4].str.join(\" \"), np.nan)\n",
    "df['kickoff_returner'] = np.where((df['play'].str.contains('Kickoff')), \n",
    "                           df[\"situation\"].str.extract(r'(\\S*\\s\\S*)(?=\\sreturn)',expand=False),np.nan)\n",
    "df['kickoff_ret_yds'] = np.where((df['play'].str.contains('Kickoff')), \n",
    "                           df[\"situation\"].str.extract(r'(?<=return\\s)(\\S*)',expand=False),np.nan)\n",
    "df['punt'] = np.where((df['play'].str.contains('Punt')),1,0)\n",
    "df['punt_yds'] = np.where((df['play'].str.contains('Punt')), \n",
    "                          df[\"situation\"].str.extract(r\"(?<=punt\\s)(\\S*)\", expand=False),0)\n",
    "df['punter'] = np.where((df['play'].str.contains('Punt')), \n",
    "                          df[\"situation\"].str.extract(r\"(\\S*\\s\\S*)(?=\\spunt)\", expand=False),np.nan)\n",
    "df['timeout'] = np.where((df['play'].str.contains('Timeout')),1,0)\n",
    "df['def_player_action'] = np.where((df['play'].str.contains('Penalty')),np.nan,df['situation']\n",
    "                            .str.extract(r\"\\((.*?)\\)\", expand=False).str.replace(\";\",','))\n",
    "df['int'] = np.where((df['play'].str.contains('Pass')&(df['situation'].str.contains('intercepted'))), 1, 0)\n",
    "df['int_player'] = np.where((df['situation'].str.contains('intercepted')),\n",
    "                            df[\"situation\"].str.extract(r'(?<=intercepted by\\s)(\\S*\\s\\S*)',expand=False),np.nan)\n",
    "df['int_ret_yds'] = np.where((df['situation'].str.contains('intercepted')),\n",
    "                            df[\"situation\"].str.extract(r'(?<=return\\s)(\\S*)',expand=False),np.nan)\n",
    "df['sack'] = np.where((df['situation'].str.contains('sack')), 1, 0)\n",
    "df['sack_yds'] = np.where((df['situation'].str.contains('sacked for loss of')), \n",
    "                           \"-\"+df[\"situation\"].str.split(\" \").str[6:7].str.join(\" \"),np.nan)\n",
    "df['fumble'] = np.where((df['situation'].str.contains('fumble')), 1, 0)\n",
    "df['fum_player'] = np.where((df['situation'].str.contains('fumble')),\n",
    "                            df['situation'].str.extract(r'(?<=fumble by\\s)(\\S*\\s\\S*)',expand=False),np.nan)\n",
    "df['fum_force_player'] = np.where((df['situation'].str.contains('fumble')),\n",
    "                    df['situation'].str.extract(r'(?<=forced by\\s)(\\S*\\s\\S*)',expand=False),np.nan)\n",
    "df['fum_recov_player'] = np.where((df['situation'].str.contains('fumble')),\n",
    "                        df['situation'].str.extract(r'(?<=recovered by\\s\\S\\S\\s)(\\S*\\s\\S*)',expand=False),np.nan)\n",
    "df['fum_recov_team'] = np.where((df['situation'].str.contains('fumble')),\n",
    "                                df['situation'].str.extract(r'(?<=recovered by\\s)(\\S*)',expand=False),np.nan)\n",
    "df['penalty'] = np.where((df['play'].str.contains('Penalty')),1,0)\n",
    "df['penalty_type'] = np.where((df['play'].str.contains('Penalty')),\n",
    "                              df[\"situation\"].str.extract(r\"^(.+?) ?(?:\\d|\\(|$)\", expand=False),np.nan)\n",
    "df['penalty_type'] = df['penalty_type'].str.split(\" \").str[2:].str.join(\" \")\n",
    "df['penalty_yds'] =  np.where((df['play'].str.contains('Penalty')),\n",
    "                            df[\"situation\"].str.extract(r'(\\S*)(?=\\syards)',expand=False),0)\n",
    "df['penalty_team'] = np.where((df['play'].str.contains('Penalty')),\n",
    "                               df[\"situation\"].str.split(\" \").str[1:2].str.join(\" \"),np.nan)\n",
    "df['penalty_player'] = np.where((df['play'].str.contains('Penalty')),\n",
    "                               df['situation'].str.extract(r\"\\((.*?)\\)\", expand=False).str.replace(\";\",','),np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf2cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionaries for some abbreviations replacements\n",
    "teams_dict = {'CC':'Cologne Centurions','IR':'Istanbul Rams','LK':'Leipzig Kings',\n",
    "                'PW':'Panthers Wroclaw','FG':'Frankfurt Galaxy','RF':'Rhein Fire',\n",
    "                'VV':'Vienna Vikings','RT':'Raiders Tirol','BD':'Barcelona Dragons',\n",
    "                'SS':'Stuttgart Surge','BT':'Berlin Thunder','HD':'Hamburg Sea Devils'}\n",
    "penalty_dict = {'IS':'IS','OD':'OD','HO':'HO','ILF':'Illegal Forward Handling','DOF':'Defensive Offside',\n",
    "                'DOG':'Delay of Game','FMM':'Facemask','ICT':'Illegal Contact','ENC':'Encroachment',\n",
    "                'ILH':'Illegal Use of Hands','PR':'PR','RPS':'Roughing the Passer',\n",
    "                'FST':'False Start','DPI':'Defensive Pass Interference','OH':'Offensive Holding',\n",
    "                'DH':'Defensive Holding','UNR':'Unnecessary Roughness','BLI':'Illegal Blindside Block',\n",
    "                'false start':'False Start'}\n",
    "quarter_dict = {'1st Quarter':'1','2nd Quarter':'2','3rd Quarter':'3','4th Quarter':'4'}\n",
    "id_dict = {'Wroclaw':\"Panthers\"}\n",
    "#using replace for some columns with dictionaries created earlier\n",
    "df.replace({\"penalty_team\":teams_dict}, inplace=True)\n",
    "df.replace({\"fum_recov_team\":teams_dict}, inplace=True)\n",
    "df.replace({\"penalty_type\":penalty_dict}, inplace=True)\n",
    "df.replace({\"qtr\":quarter_dict}, inplace=True)\n",
    "df.replace({\"home_team\":id_dict,\"away_team\":id_dict}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de304ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "df.to_csv('elf_plays_2022.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
